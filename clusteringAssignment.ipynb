{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat is an unsupervised learning approach? Why is it needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In unsupervised learning, the algorithm tries to find out the similarities between the data points and group them into clusters. \n",
    "This algorithm is used when we dont have a labelled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A cluster is a collection of objects which are similar amongst themselves but are dissimilar to the objects belonging\n",
    "to a different cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tHow do clustering and classification differ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification is the process of classifying the data with the help of class labels whereas Clustering doesnt have predefined\n",
    "class label and it groups similar instances based on their similarities.\n",
    "Classificaiton is a supervised learning  and Clustering is unsupervised learning technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.\tWhat are the various applications of clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. customer segmentation\n",
    "2. Data Analysis\n",
    "3. Outlier detection\n",
    "4. Semi-supervised learning\n",
    "5. Segmenting an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.\tHow does clustering play a role in supervised learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering is an unsupervised machine learning approach, but can be used to improve the accuracy of supervised machine \n",
    "learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.\tWhat are the requirements to be met by a clustering algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It should be scalable.\n",
    "It should be able to deal with attributes of different types.\n",
    "It should be able to discover arbitrary shape clusters.\n",
    "It should have an inbuilt ability to deal with noise and outliers.\n",
    "The clusters should not vary with the order of input records.\n",
    "It should be able to handle data of high dimensions.\n",
    "It should be easy to interpret and use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.\tDiscuss the different approaches for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Agglomerative - This approach first considers all the points as individual clusters and then finds out the similarity \n",
    "between two points, puts them into a cluster. Then it goes on finding similar points and clusters until there is only one cluster left\n",
    "2. Divisive - It is opposite of the agglomerative approach. It first considers all the points to be part of one big cluster \n",
    "and in the subsequent steps tries to find out the points/ clusters which are least similar to each other and then breaks the bigger cluster into smaller ones. This continues until there are as many clusters as there are datapoints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.\tWhat is WCSS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Within Cluster Sum of Square. It is the sum of the squared distance between each member of the cluster and its centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.\tDiscuss the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a relationship between WCSS(Inertia) and the number of clusters. This elbow method helps us to choose the right number\n",
    "of clusters that can be used in K-Means algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.\tWhat is the significance of ‘K’ in K-Means and how is it calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K here means the number of clusters that will be used in K-Means algorithm. It is calculated by the elbow method where we choose a \n",
    "range of K values and plot it to see with the number of increase in K value how much is the WCSS decreasing. Generally we see a \n",
    "elbow being formed in a plot which means as the number of clusters starts to increase, the WCSS decreases steeply but after sometime\n",
    "it smoothens. So the optimal K value wil be the point when the WCSS and cluster becomes smoother. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.\tDiscuss the step by step implementation of K-Means Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "After the initial EDA to the dataset. We can select the features with which we want to build the algorithm. Then with elbow method\n",
    "we calculate the right number of clusters to be used. The next step would be to apply the parameter with cluster size in the K-means\n",
    "algorithm. The algorithm first picks up random centroid values, then based on the Euclidean distance calculation it keeps on \n",
    "moving to the central place in a cluster till there is no change in the movement of datapoints. Once the model is build, we can\n",
    "predict the values in the dataset. Then you can also test it by giving some random values or values from your dataset\n",
    "to see how it is predicting. You can also plot the clusters in graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.\tWhat are the challenges with K-Means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. we need to specify how many clusters needs to be taken beforehand\n",
    "2. It is required to run the algorithm multiple times to avoid a sub-optimal solution\n",
    "3. K-Means does not work very well when the clusters have varying sizes, different densities, or non-spherical shapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13.\tDiscuss the various improvements in K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. K-Means++ , this parameter value tendst to select the centroids that are distant from one another.\n",
    "2.Instead of using the full dataset at each iteration, the algorithm is capable of using mini-batches, \n",
    "moving the centroids just slightly at each iteration.Scikit-Learn implements this algorithm in the MiniBatchKMeans class\n",
    "3. It considerably accelerates the algorithm by avoiding many unnecessary distance calculations: this is achieved by exploiting \n",
    "the triangle inequality and by keeping track of lower and upper bounds for distances between instances and centroids. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Clustering:\n",
    "14.\tDiscuss the agglomerative and divisive clustering approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Agglomerative: This approach first considers all the points as individual clusters and then finds out the similarity \n",
    "between two points, puts them into a cluster. Then it goes on finding similar points and clusters until there is only \n",
    "one cluster left i.e., all points belong to a big cluster. This is also called the bottom-up approach.\n",
    "\n",
    "Divisive:  It is opposite of the agglomerative approach. It first considers all the points to be part of one big cluster \n",
    "and in the subsequent steps tries to find out the points/ clusters which are least similar to each other and then breaks\n",
    "the bigger cluster into smaller ones. This continues until there are as many clusters as there are datapoints. This is also \n",
    "called the top-down approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15.\tWhat are dendrograms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dedrogram: A dendrogram is a diagram that shows the hierarchical relationship between objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.\tDiscuss the Hierarchical clustering in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is bottom up approach cluster building model where each data point is considered as individual clusters and they are grouped\n",
    "together based on the similiarities in a bigger clusters and this gouping goes on till we have all the small clusters in one cluster.\n",
    "We consider the Euclidean distance to group the clusters. By drawing the dendrogram, we would in a position to select the \n",
    "right number of clusters to be used in the algorithem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.\tDiscuss the various linkage methods for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Single Linkage: cluster distance = smallest pairwise distance\n",
    "Complete Linkage: cluster distance = largest pairwise distance\n",
    "Average Linkage: cluster distance = average pairwise distance\n",
    "Centroid Linkage: cluster distance= distance between the centroids of the clusters\n",
    "Ward’s Linkage: cluster criteria= Minimize the variance in the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18.\tDiscuss the differences between K-Means and Hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K-Means follows top down approach and Hierarchial clustering follows bottom up approach\n",
    "We need to mention the K value beforehand in K means but in Hierarchial clustering it is not required to given beforehand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN\n",
    "19.\tDiscuss the basic terms used in DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is an unsupervised machine learning algorithm.This algorithm defines clusters as continuous regions of high density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20.\tDiscuss the step by step implementation of DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The algorithm starts with a random point in the dataset and its neighbouring points are identified based on the eps value.\n",
    "If the point contains greater than or equal points than the min_pts, then the cluster is formed and this point becomes a core point, \n",
    "else it’s considered as noise. The thing to note here is that a point initially classified as noise can later become a border point \n",
    "if it’s in the eps radius of a core point.\n",
    "If the point is a core point, then all its neighbours become a part of the cluster. If the points in the neighbourhood turn out to be\n",
    "core points then their neighbours are also part of the cluster. Repeat the steps above until all points are classified \n",
    "into different clusters or noises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster Evaluation\n",
    "21.\tWhat are the aspects of cluster validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "External: Compare your cluster to the ground truth.\n",
    "Internal: Evaluating the cluster without reference to external data.\n",
    "Reliability: The clusters are not formed by chance(randomly)- some statistical framework can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22.\tWhat is a confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23.\tWhat is Jaccard’s coefficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a cluster validation technique where it checks how many positive data points have been correctly classifed for both \n",
    "algorithm and the Ground Truth. The formula is Total Agree (only positive) / Total points (SS+DD/(SS+DD+SD+DS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24.\tWhat is Rand Index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is a cluster validation technique where it checks how many data points have been correctly classifed for both algorithm\n",
    "and the Ground Truth. The formula is Total Agree / Total points (SS+DD/(SS+DD+SD+DS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25.\tWhat is the entropy of a cluster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26.\tDiscuss the purity of a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he purity is the total percentage of data points clustered correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27.\tWhat are cohesion and compression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cohesion: How closely the objects in the same cluster are related to each other. It is the within-cluster sum of squared distances.\n",
    "Separation: How different the objects in different clusters are and how distinct a well-separated cluster is from other clusters.\n",
    "It is the between cluster sum of squared distances. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28.\tWhat are the steps for AWS deployment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "One needs to have the necessary files like the python files, requirements, python config in ebextension folder. These all files\n",
    "have to be zipped in a folder. \n",
    "Open the AWS with your sign in credentials if not create one.\n",
    "click on build web app\n",
    "Give application name, platform as Python and upload your zipped file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29.\tWhat difficulties did you face while deploying to AWS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I have  received error multiple times while uploading the zipped file while deploying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
